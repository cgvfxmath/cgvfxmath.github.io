---
layout: post
title: "Proof of PCA"
author: "wano"
excerpt_separator: <!--more-->
tags: ['math']
use_math: true
lastmode: 2023-04-23 13:00:00
sitemap:
  changefreq: weekly
  priority: 0.5
---

Why eigenvectors of a covariance matrix become principal component axes<!--more-->

*본 포스트에는 수식이 포함되어 있습니다. 분수 등의 수식이 정상적으로 보이지 않는 경우에는 수식을 마우스 오른쪽 버튼으로 클릭한 후 "Math Renderer"를 SVG로 바꿔주세요.*


$n$개의 **특성(feature)**을 가지는 확률변수 $X$에 대한 $n$개의 **표본(sample)** $p_i$가 주어졌다고 가정해보겠습니다.

중심점 이동(centering), 스케일링(scaling) 등의 전처리 과정(pre-processing)을 거친 데이터는 다음과 같은 $m \times n$ 행렬 $\mathbf{D}$로 나타낼 수 있습니다.

$
\mathbf{D}

\; = \;

\begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1n} \\
x_{11} & x_{22} & \cdots & x_{2n} \\
\vdots & \vdots & & \vdots \\
x_{m1} & x_{m2} & \cdots & x_{mn}
\end{bmatrix}

\; = \;

\begin{bmatrix}
- \mathbf{p}_1 - \\
- \mathbf{p}_2 - \\
\vdots \\
- \mathbf{p}_m - \\
\end{bmatrix}

\; = \;

\begin{bmatrix}
| & | & \cdots & | \\
\mathbf{f}_1 & \mathbf{f}_2 & \cdots & \mathbf{f}_n \\
| & | & \cdots & |
\end{bmatrix}
$

여기서 $\mathbf{p}_i$와 $\mathbf{f}_j$는 각각 행렬 $\mathbf{D}$의 $i$번째 행과 $j$번째 열을 의미합니다. 즉, $\mathbf{p}_i$는 $i$번째 **표본(sample)**이고, $\mathbf{f}_j$는 $j$번째 **특성(feature)**을 나타냅니다. 따라서 $m$은 표본의 개수이고, $n$은 특성의 개수를 의미합니다.

이때 $a$번째

